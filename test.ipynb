{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json saved to /yuming/CoTr/data/nnUNet_raw_data_base/nnUNet_raw_data/Task071_AbdomenCT/dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 设置你的 imagesTr 和 labelsTr 路径\n",
    "imagesTr_dir = \"/yuming/CoTr/data/nnUNet_raw_data_base/nnUNet_raw_data/Task071_AbdomenCT/imagesTr\"\n",
    "labelsTr_dir = \"/yuming/CoTr/data/nnUNet_raw_data_base/nnUNet_raw_data/Task071_AbdomenCT/labelsTr\"\n",
    "# imagesTs_dir = \"/yuming/CoTr/data/nnUNet_raw_data_base/nnUNet_raw_data/Task072_AbdomenMR/imagesTs\"\n",
    "\n",
    "# 读取 imagesTr 目录下所有 .nii.gz 文件\n",
    "images = sorted([f for f in os.listdir(imagesTr_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "# 自动构建 training 列表\n",
    "training = []\n",
    "for img in images:\n",
    "    # 去掉最后一个 _0000\n",
    "    img_base = img.replace(\"_0000\", \"\").replace(\".nii.gz\", \"\")  # 去掉_0000 和 后缀\n",
    "    img_path = \"./imagesTr/\" + img_base + \".nii.gz\"\n",
    "    label_path = \"./labelsTr/\" + img_base + \".nii.gz\"\n",
    "    training.append({\"image\": img_path, \"label\": label_path})\n",
    "\n",
    "# # 2. 构建 test 列表\n",
    "# test_images = sorted([f for f in os.listdir(imagesTs_dir) if f.endswith(\".nii.gz\")])\n",
    "# test = []\n",
    "# for img in test_images:\n",
    "#     img_base = img.replace(\"_0000\", \"\").replace(\".nii.gz\", \"\")  # 去掉_0000 和 后缀\n",
    "#     test.append(f\"./imagesTs/{img_base}.nii.gz\")\n",
    "\n",
    "# 创建最终的 dataset.json\n",
    "dataset_json = {\n",
    "    \"name\": \"Dataset701_FLARE2022\",\n",
    "    \"description\": \"This dataset was from MICCAI AMOS 2022 Challenge...\",\n",
    "    \"tensorImageSize\": \"3D\",\n",
    "    \"reference\": \"MICCAI FLARE 2022\",\n",
    "    \"licence\": \"CC BY-SA 4.0\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"modality\": {\n",
    "        \"0\": \"CT\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"0\": \"background\",\n",
    "        \"1\": \"liver\",\n",
    "        \"2\": \"right kidney\",\n",
    "        \"3\": \"spleen\",\n",
    "        \"4\": \"pancreas\",\n",
    "        \"5\": \"aorta\",\n",
    "        \"6\": \"inferior vena cava\",\n",
    "        \"7\": \"right adrenal gland\",\n",
    "        \"8\": \"left adrenal gland\",\n",
    "        \"9\": \"gallbladder\",\n",
    "        \"10\": \"esophagus\",\n",
    "        \"11\": \"stomach\",\n",
    "        \"12\": \"duodenum\",\n",
    "        \"13\": \"left kidney\"\n",
    "    },\n",
    "    \"numTraining\": len(training),\n",
    "    \"numTest\": 0,\n",
    "    \"training\": training,\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "# 保存到 dataset.json\n",
    "output_path = \"/yuming/CoTr/data/nnUNet_raw_data_base/nnUNet_raw_data/Task071_AbdomenCT/dataset.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "print(f\"dataset.json saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'collections.OrderedDict'>\n",
      "odict_keys(['train', 'val'])\n",
      "[OrderedDict([('train', ['amos_0507', 'amos_0508', 'amos_0510', 'amos_0514', 'amos_0517', 'amos_0518', 'amos_0522', 'amos_0530', 'amos_0532', 'amos_0538', 'amos_0540', 'amos_0541', 'amos_0544', 'amos_0545', 'amos_0546', 'amos_0547', 'amos_0548', 'amos_0549', 'amos_0550', 'amos_0551', 'amos_0552', 'amos_0553', 'amos_0554', 'amos_0555', 'amos_0556', 'amos_0557', 'amos_0558', 'amos_0559', 'amos_0561', 'amos_0562', 'amos_0563', 'amos_0568', 'amos_0570', 'amos_0571', 'amos_0572', 'amos_0573', 'amos_0575', 'amos_0576', 'amos_0578', 'amos_0580', 'amos_0581', 'amos_0582', 'amos_0583', 'amos_0584', 'amos_0585', 'amos_0586', 'amos_0587', 'amos_0588', 'amos_0589', 'amos_0590', 'amos_0591', 'amos_0592', 'amos_0593', 'amos_0594', 'amos_0595', 'amos_0596', 'amos_0597', 'amos_0598', 'amos_0599', 'amos_0600']), ('val', ['amos_7016', 'amos_7164', 'amos_7236', 'amos_7237', 'amos_7240', 'amos_7244', 'amos_7261', 'amos_7264', 'amos_7296', 'amos_7324', 'amos_7362', 'amos_7384', 'amos_7387', 'amos_7398', 'amos_7438', 'amos_7458', 'amos_7492', 'amos_7562', 'amos_7626', 'amos_7671', 'amos_7776', 'amos_7784', 'amos_7785', 'amos_7789', 'amos_7799', 'amos_7801', 'amos_7813', 'amos_7890', 'amos_7891', 'amos_7894', 'amos_7898', 'amos_7956', 'amos_7958', 'amos_7959', 'amos_7961', 'amos_7980', 'amos_8004', 'amos_8026', 'amos_8027', 'amos_8028', 'amos_8069', 'amos_8082', 'amos_8117', 'amos_8140', 'amos_8141', 'amos_8149', 'amos_8150', 'amos_8178', 'amos_8179', 'amos_8186'])])]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/yuming/CoTr/data/nnUNet_preprocessed/Task071_AbdomenCT/splits_final.pkl', 'rb') as f:\n",
    "    plans_amos = pickle.load(f)\n",
    "# with open('/yuming/CoTr/data/splits_final.pkl', 'rb') as f:\n",
    "#     plans_BCV = pickle.load(f)\n",
    "# with open('/yuming/CoTr/plans_my_amos.pkl', 'rb') as f:\n",
    "#     plans_my_amos = pickle.load(f)\n",
    "# 在 plans 里查找 fold 列表，通常叫做 plans['splits'] 或者 plans['folds']\n",
    "# print(plans_amos)\n",
    "print(type(plans_amos))           # <class 'list'>\n",
    "print(type(plans_amos[0]))        # <class 'collections.OrderedDict'>\n",
    "print(plans_amos[0].keys())       # odict_keys(['train', 'val'])\n",
    "print(plans_amos)       # odict_keys(['train', 'val'])\n",
    "\n",
    "# print(plans.get('splits') or plans.get('folds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ids ['amos_0507', 'amos_0508', 'amos_0510', 'amos_0514', 'amos_0517', 'amos_0518', 'amos_0522', 'amos_0530', 'amos_0532', 'amos_0538', 'amos_0540', 'amos_0541', 'amos_0544', 'amos_0545', 'amos_0546', 'amos_0547', 'amos_0548', 'amos_0549', 'amos_0550', 'amos_0551', 'amos_0552', 'amos_0553', 'amos_0554', 'amos_0555', 'amos_0556', 'amos_0557', 'amos_0558', 'amos_0559', 'amos_0561', 'amos_0562', 'amos_0563', 'amos_0568', 'amos_0570', 'amos_0571', 'amos_0572', 'amos_0573', 'amos_0575', 'amos_0576', 'amos_0578', 'amos_0580', 'amos_0581', 'amos_0582', 'amos_0583', 'amos_0584', 'amos_0585', 'amos_0586', 'amos_0587', 'amos_0588', 'amos_0589', 'amos_0590', 'amos_0591', 'amos_0592', 'amos_0593', 'amos_0594', 'amos_0595', 'amos_0596', 'amos_0597', 'amos_0598', 'amos_0599', 'amos_0600']\n",
      "✔ 已生成 /yuming/CoTr/dataset/mr/splits_final.pkl\n",
      "  train: 60 条 ID，示例：['amos_0507', 'amos_0508', 'amos_0510', 'amos_0514', 'amos_0517']\n",
      "  val:   50 条 ID，示例：['amos_7016', 'amos_7164', 'amos_7236', 'amos_7237', 'amos_7240']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "# —— 配置区 —— #\n",
    "train_dir = \"/yuming/Dataset702_AbdomenMR/imagesTr\"  # 改为你的训练数据文件夹\n",
    "val_dir   = \"/yuming/Dataset702_AbdomenMR/labelsTs\"    # 改为你的验证/测试数据文件夹\n",
    "output_path = \"/yuming/CoTr/dataset/mr/splits_final.pkl\"             # 输出文件名\n",
    "# ———————— #\n",
    "\n",
    "def extract_id(fname):\n",
    "    \"\"\"\n",
    "    针对训练图像：去掉 _0000.nii.gz，保留 ID\n",
    "    针对标签文件：去掉 .nii.gz，保留 ID\n",
    "    \"\"\"\n",
    "    base = os.path.basename(fname)\n",
    "    \n",
    "    if base.endswith(\"_0000.nii.gz\"):\n",
    "        return base.replace(\"_0000.nii.gz\", \"\")\n",
    "    elif base.endswith(\".nii.gz\"):\n",
    "        return base.replace(\".nii.gz\", \"\")\n",
    "    else:\n",
    "        return base  # fallback\n",
    "\n",
    "def collect_ids(folder):\n",
    "    ids = set()\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(('.nii.gz', '.nii')):\n",
    "            ids.add(extract_id(fn))\n",
    "    return sorted(ids)\n",
    "\n",
    "# 收集\n",
    "train_ids = collect_ids(train_dir)\n",
    "print(\"train_ids\", train_ids)\n",
    "val_ids   = collect_ids(val_dir)\n",
    "\n",
    "# 构造 OrderedDict 列表\n",
    "plans = [\n",
    "    OrderedDict([\n",
    "        (\"train\", train_ids),\n",
    "        (\"val\",   val_ids),\n",
    "    ])\n",
    "]\n",
    "\n",
    "# 序列化到 pkl\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(plans, f)\n",
    "\n",
    "print(f\"✔ 已生成 {output_path}\")\n",
    "print(f\"  train: {len(train_ids)} 条 ID，示例：{train_ids[:5]}\")\n",
    "print(f\"  val:   {len(val_ids)} 条 ID，示例：{val_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cotr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
